{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('FPgo-hI7OiE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如何使用和开发微信聊天机器人的系列教程\n",
    "# A workshop to develop & use an intelligent and interactive chat-bot in WeChat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WeChat is a popular social media app, which has more than 800 million monthly active users.\n",
    "\n",
    "<img src='reference/logo.png' width=12% style=\"float: right;\">\n",
    "<img src='reference/WeChat_SamGu_QR.png' width=10% style=\"float: right;\">\n",
    "\n",
    "### http://www.KudosData.com\n",
    "\n",
    "by: Sam.Gu@KudosData.com\n",
    "\n",
    "\n",
    "October 2018 : Update to support Python 3 in local machine, e.g. iss-vm.\n",
    "\n",
    "\n",
    "April 2017 ========== Scan the QR code to become trainer's friend in WeChat ========>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二课：图像识别和处理\n",
    "### Lesson 2: Image Recognition & Processing\n",
    "\n",
    "* 识别图片消息中的物体名字 (Recognize objects in image)\n",
    "        [1] 物体名 (General Object)\n",
    "        [2] 地标名 (Landmark Object)\n",
    "        [3] 商标名 (Logo Object)\n",
    "\n",
    "* 识别图片消息中的文字 (OCR: Extract text from image)\n",
    "        包含简单文本翻译 (Call text translation API)\n",
    "        \n",
    "* 识别人脸 (Recognize human face)\n",
    "        基于人脸的表情来识别喜怒哀乐等情绪 (Identify sentiment and emotion from human face)\n",
    "\n",
    "* 不良内容识别 (Explicit Content Detection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Google Cloud Platform's Machine Learning APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the same API console, choose \"Dashboard\" on the left-hand menu and \"Enable API\".\n",
    "\n",
    "Enable the following APIs for your project (search for them) if they are not already enabled:\n",
    "<ol>\n",
    "<li> Google Translate API </li>\n",
    "<li> Google Cloud Vision API </li>\n",
    "<li> Google Natural Language API </li>\n",
    "<li> Google Cloud Speech API </li>\n",
    "</ol>\n",
    "\n",
    "Finally, because we are calling the APIs from Python (clients in many other languages are available), let's install the Python package (it's not installed by default on Datalab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2016 Google Inc.\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\"); \n",
    "# !pip install --upgrade google-api-python-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入需要用到的一些功能程序库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install the client library\n",
    "# !pip install --upgrade google-cloud-vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types\n",
    "\n",
    "# from google.cloud import vision_v1p2beta1\n",
    "# from google.cloud.vision_v1p2beta1 import types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before proceeding, ensure to ENABLE this cloud API, e.g. via web console https://console.cloud.google.com "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Vision API\n",
    "\n",
    "# (1) Instantiates a client - using GOOGLE_APPLICATION_CREDENTIALS\n",
    "# client = vision.ImageAnnotatorClient()\n",
    "\n",
    "# (2) Instantiates a client - using 'service account json' file\n",
    "client = vision.ImageAnnotatorClient.from_service_account_json(\n",
    "        \"/media/sf_vm_shared_folder/000-cloud-api-key/mtech-ai-7b7e049cf5f6.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Use cloud APIs in native forms:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Landmark Detection\n",
    "https://cloud.google.com/vision/docs/detecting-landmarks#vision-landmark-detection-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def issgz_landmark_detection(image):\n",
    "    \"\"\"Detects landmarks in the file.\"\"\"\n",
    "    from google.cloud import vision\n",
    "    \n",
    "##################################################################\n",
    "#     client = vision.ImageAnnotatorClient()\n",
    "# \n",
    "#     client = vision.ImageAnnotatorClient.from_service_account_json(\n",
    "#         \"/media/sf_vm_shared_folder/000-cloud-api-key/mtech-ai-7b7e049cf5f6.json\")\n",
    "##################################################################\n",
    "\n",
    "    with io.open(image, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    response = client.landmark_detection(image=image)\n",
    "    landmarks = response.landmark_annotations\n",
    "    print('Landmarks:')\n",
    "\n",
    "    for landmark in landmarks:\n",
    "        print(landmark.description)\n",
    "        for location in landmark.locations:\n",
    "            lat_lng = location.lat_lng\n",
    "            print('Latitude {}'.format(lat_lng.latitude))\n",
    "            print('Longitude {}'.format(lat_lng.longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landmarks:\n",
      "Statue of Liberty\n",
      "Latitude 40.689261\n",
      "Longitude -74.044482\n"
     ]
    }
   ],
   "source": [
    "issgz_landmark_detection('image/new-york-statue-of-liberty.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landmarks:\n"
     ]
    }
   ],
   "source": [
    "issg_landmark_detection('image/ZhanGu.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Detection\n",
    "https://cloud.google.com/vision/docs/quickstart-client-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the image into memory\n",
    "with io.open('image/ZhanGu.png', 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "\n",
    "image = types.Image(content=content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "text\n",
      "product\n",
      "presentation\n",
      "online advertising\n",
      "product\n",
      "software\n",
      "media\n",
      "font\n",
      "communication\n",
      "service\n"
     ]
    }
   ],
   "source": [
    "# Performs label detection on the image file\n",
    "response = client.label_detection(image=image)\n",
    "labels = response.label_annotations\n",
    "\n",
    "print('Labels:')\n",
    "for label in labels:\n",
    "    print(label.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def issgz_label_detection(image_file, max_results=4):\n",
    "    \"\"\"Uses the Vision API to detect labels in the given file.\n",
    "\n",
    "    Args:\n",
    "        face_file: A file-like object containing an image with faces.\n",
    "\n",
    "    Returns:\n",
    "        An array of lABEL objects with information about the picture.\n",
    "    \"\"\"\n",
    "# \n",
    "#     client = vision.ImageAnnotatorClient.from_service_account_json(\n",
    "#         \"/media/sf_vm_shared_folder/000-cloud-api-key/mtech-ai-7b7e049cf5f6.json\")\n",
    "\n",
    "    # Loads the image into memory\n",
    "#     with open(image_file, 'rb') as image:\n",
    "    with io.open(image_file, 'rb') as image:\n",
    "        content = image.read()\n",
    "\n",
    "    image = types.Image(content=content)        \n",
    "        \n",
    "    # Performs label detection on the image file\n",
    "    response = client.label_detection(image=image)\n",
    "    labels = response.label_annotations\n",
    "\n",
    "    print('Labels:')\n",
    "    for label in labels:\n",
    "        print(label.description)\n",
    "\n",
    "#     return client.label_detection(image=image).label_annotations\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "text\n",
      "product\n",
      "presentation\n",
      "online advertising\n",
      "product\n",
      "software\n",
      "media\n",
      "font\n",
      "communication\n",
      "service\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mid: \"/m/07s6nbt\"\n",
       "description: \"text\"\n",
       "score: 0.8938024044036865\n",
       "topicality: 0.8938024044036865\n",
       ", mid: \"/m/02n3pb\"\n",
       "description: \"product\"\n",
       "score: 0.8075989484786987\n",
       "topicality: 0.8075989484786987\n",
       ", mid: \"/m/02y3rj\"\n",
       "description: \"presentation\"\n",
       "score: 0.7253251671791077\n",
       "topicality: 0.7253251671791077\n",
       ", mid: \"/m/05b1rx\"\n",
       "description: \"online advertising\"\n",
       "score: 0.7024965882301331\n",
       "topicality: 0.7024965882301331\n",
       ", mid: \"/m/01jwgf\"\n",
       "description: \"product\"\n",
       "score: 0.695496141910553\n",
       "topicality: 0.695496141910553\n",
       ", mid: \"/m/01mf0\"\n",
       "description: \"software\"\n",
       "score: 0.6777704358100891\n",
       "topicality: 0.6777704358100891\n",
       ", mid: \"/m/03qh03g\"\n",
       "description: \"media\"\n",
       "score: 0.6681089401245117\n",
       "topicality: 0.6681089401245117\n",
       ", mid: \"/m/03gq5hm\"\n",
       "description: \"font\"\n",
       "score: 0.6665086150169373\n",
       "topicality: 0.6665086150169373\n",
       ", mid: \"/m/01lhf\"\n",
       "description: \"communication\"\n",
       "score: 0.6425229907035828\n",
       "topicality: 0.6425229907035828\n",
       ", mid: \"/m/018tkd\"\n",
       "description: \"service\"\n",
       "score: 0.6124182939529419\n",
       "topicality: 0.6124182939529419\n",
       "]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issgz_label_detection('image/ZhanGu.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detection\n",
    "https://cloud.google.com/vision/docs/face-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(face_file, max_results=4):\n",
    "    \"\"\"Uses the Vision API to detect faces in the given file.\n",
    "\n",
    "    Args:\n",
    "        face_file: A file-like object containing an image with faces.\n",
    "\n",
    "    Returns:\n",
    "        An array of Face objects with information about the picture.\n",
    "    \"\"\"\n",
    "# \n",
    "#     client = vision.ImageAnnotatorClient.from_service_account_json(\n",
    "#         \"/media/sf_vm_shared_folder/000-cloud-api-key/mtech-ai-7b7e049cf5f6.json\")\n",
    "    \n",
    "    content = face_file.read()\n",
    "    image = types.Image(content=content)\n",
    "\n",
    "    return client.face_detection(image=image).face_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_faces(image, faces, output_filename):\n",
    "    \"\"\"Draws a polygon around the faces, then saves to output_filename.\n",
    "\n",
    "    Args:\n",
    "      image: a file containing the image with the faces.\n",
    "      faces: a list of faces found in the file. This should be in the format\n",
    "          returned by the Vision API.\n",
    "      output_filename: the name of the image file to be created, where the\n",
    "          faces have polygons drawn around them.\n",
    "    \"\"\"\n",
    "    im = Image.open(image)\n",
    "    draw = ImageDraw.Draw(im)\n",
    "\n",
    "    for face in faces:\n",
    "        box = [(vertex.x, vertex.y)\n",
    "               for vertex in face.bounding_poly.vertices]\n",
    "        draw.line(box + [box[0]], width=5, fill='#00ff00')\n",
    "\n",
    "    im.save(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def issgz_face_detection(input_filename, output_filename='image/DetectedFace.png', max_results=5):\n",
    "    with open(input_filename, 'rb') as image:\n",
    "        faces = detect_face(image, max_results)\n",
    "        print('Found {} face{}'.format(\n",
    "            len(faces), '' if len(faces) == 1 else 's'))\n",
    "\n",
    "        print('Writing to file {}'.format(output_filename))\n",
    "        # Reset the file pointer, so we can read the file again\n",
    "        image.seek(0)\n",
    "        highlight_faces(image, faces, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 face\n",
      "Writing to file image/ZhanGuDetectedFace.png\n"
     ]
    }
   ],
   "source": [
    "issgz_face_detection('image/ZhanGu.png', 'image/ZhanGuDetectedFace.png', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Text Detection\n",
    "https://cloud.google.com/vision/docs/fulltext-annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from enum import Enum\n",
    "import io\n",
    "\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "class FeatureType(Enum):\n",
    "    PAGE = 1\n",
    "    BLOCK = 2\n",
    "    PARA = 3\n",
    "    WORD = 4\n",
    "    SYMBOL = 5\n",
    "\n",
    "\n",
    "def draw_boxes(image, bounds, color):\n",
    "    \"\"\"Draw a border around the image using the hints in the vector list.\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for bound in bounds:\n",
    "        draw.polygon([\n",
    "            bound.vertices[0].x, bound.vertices[0].y,\n",
    "            bound.vertices[1].x, bound.vertices[1].y,\n",
    "            bound.vertices[2].x, bound.vertices[2].y,\n",
    "            bound.vertices[3].x, bound.vertices[3].y], None, color)\n",
    "    return image\n",
    "\n",
    "\n",
    "def get_document_bounds(image_file, feature):\n",
    "    \"\"\"Returns document bounds given an image.\"\"\"\n",
    "    \n",
    "        \n",
    "##################################################################\n",
    "#     client = vision.ImageAnnotatorClient()\n",
    "# \n",
    "#     client = vision.ImageAnnotatorClient.from_service_account_json(\n",
    "#         \"/media/sf_vm_shared_folder/000-cloud-api-key/mtech-ai-7b7e049cf5f6.json\")\n",
    "##################################################################\n",
    "\n",
    "    bounds = []\n",
    "\n",
    "    with io.open(image_file, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = types.Image(content=content)\n",
    "\n",
    "    response = client.document_text_detection(image=image)\n",
    "    document = response.full_text_annotation\n",
    "\n",
    "    # Collect specified feature bounds by enumerating all document features\n",
    "    for page in document.pages:\n",
    "        for block in page.blocks:\n",
    "            for paragraph in block.paragraphs:\n",
    "                for word in paragraph.words:\n",
    "                    for symbol in word.symbols:\n",
    "                        if (feature == FeatureType.SYMBOL):\n",
    "                            bounds.append(symbol.bounding_box)\n",
    "\n",
    "                    if (feature == FeatureType.WORD):\n",
    "                        bounds.append(word.bounding_box)\n",
    "\n",
    "                if (feature == FeatureType.PARA):\n",
    "                    bounds.append(paragraph.bounding_box)\n",
    "\n",
    "            if (feature == FeatureType.BLOCK):\n",
    "                bounds.append(block.bounding_box)\n",
    "\n",
    "        if (feature == FeatureType.PAGE):\n",
    "            bounds.append(block.bounding_box)\n",
    "\n",
    "    # The list `bounds` contains the coordinates of the bounding boxes.\n",
    "    return bounds\n",
    "\n",
    "\n",
    "def issgz_document_text_detection(filein, fileout):\n",
    "    image = Image.open(filein)\n",
    "    bounds = get_document_bounds(filein, FeatureType.PAGE)\n",
    "    draw_boxes(image, bounds, 'blue')\n",
    "    bounds = get_document_bounds(filein, FeatureType.PARA)\n",
    "    draw_boxes(image, bounds, 'red')\n",
    "    bounds = get_document_bounds(filein, FeatureType.WORD)\n",
    "    draw_boxes(image, bounds, 'yellow')\n",
    "\n",
    "    if fileout is not 0:\n",
    "        image.save(fileout)\n",
    "    else:\n",
    "        image.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "issgz_document_text_detection('image/ZhanGu.png', 'image/ZhanGuDocumentText.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Deteciton\n",
    "https://cloud.google.com/vision/docs/internet-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import io\n",
    "\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types\n",
    "\n",
    "\n",
    "def annotate(path):\n",
    "    \"\"\"Returns web annotations given the path to an image.\"\"\"\n",
    "    \n",
    "##################################################################\n",
    "#     client = vision.ImageAnnotatorClient()\n",
    "# \n",
    "#     client = vision.ImageAnnotatorClient.from_service_account_json(\n",
    "#         \"/media/sf_vm_shared_folder/000-cloud-api-key/mtech-ai-7b7e049cf5f6.json\")\n",
    "##################################################################\n",
    "\n",
    "    if path.startswith('http') or path.startswith('gs:'):\n",
    "        image = types.Image()\n",
    "        image.source.image_uri = path\n",
    "\n",
    "    else:\n",
    "        with io.open(path, 'rb') as image_file:\n",
    "            content = image_file.read()\n",
    "\n",
    "        image = types.Image(content=content)\n",
    "\n",
    "    web_detection = client.web_detection(image=image).web_detection\n",
    "\n",
    "    return web_detection\n",
    "\n",
    "\n",
    "def issgz_web_detection(annotations):\n",
    "    \"\"\"Prints detected features in the provided web annotations.\"\"\"\n",
    "    if annotations.pages_with_matching_images:\n",
    "        print('\\n{} Pages with matching images retrieved'.format(\n",
    "            len(annotations.pages_with_matching_images)))\n",
    "\n",
    "        for page in annotations.pages_with_matching_images:\n",
    "            print('Url   : {}'.format(page.url))\n",
    "\n",
    "    if annotations.full_matching_images:\n",
    "        print('\\n{} Full Matches found: '.format(\n",
    "              len(annotations.full_matching_images)))\n",
    "\n",
    "        for image in annotations.full_matching_images:\n",
    "            print('Url  : {}'.format(image.url))\n",
    "\n",
    "    if annotations.partial_matching_images:\n",
    "        print('\\n{} Partial Matches found: '.format(\n",
    "              len(annotations.partial_matching_images)))\n",
    "\n",
    "        for image in annotations.partial_matching_images:\n",
    "            print('Url  : {}'.format(image.url))\n",
    "\n",
    "    if annotations.web_entities:\n",
    "        print('\\n{} Web entities found: '.format(\n",
    "              len(annotations.web_entities)))\n",
    "\n",
    "        for entity in annotations.web_entities:\n",
    "            print('Score      : {}'.format(entity.score))\n",
    "            print('Description: {}'.format(entity.description))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 Web entities found: \n",
      "Score      : 1.1235586404800415\n",
      "Description: Online advertising\n",
      "Score      : 0.6304581761360168\n",
      "Description: Public Relations\n",
      "Score      : 0.6198512315750122\n",
      "Description: Logo\n",
      "Score      : 0.6096217036247253\n",
      "Description: Brand\n",
      "Score      : 0.5968000292778015\n",
      "Description: Advertising\n",
      "Score      : 0.5778824687004089\n",
      "Description: Display advertising\n",
      "Score      : 0.5112000107765198\n",
      "Description: Product\n",
      "Score      : 0.4587489664554596\n",
      "Description: Font\n",
      "Score      : 0.42260000109672546\n",
      "Description: \n",
      "Score      : 0.42260000109672546\n",
      "Description: LinkedIn\n"
     ]
    }
   ],
   "source": [
    "issgz_web_detection(annotate('image/ZhanGu.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Wrap cloud APIs into Functions() for conversational virtual assistant (VA):</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器智能API接口控制参数 (Define control parameters for API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control parameter for Image API:\n",
    "parm_image_maxResults = 10 # max objects or faces to be extracted from image analysis\n",
    "\n",
    "# control parameter for Language Translation API:\n",
    "parm_translation_origin_language = '' # original language in text: to be overwriten by TEXT_DETECTION\n",
    "parm_translation_target_language = 'zh' # target language for translation: Chinese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### * 识别图片消息中的物体名字 (Recognize objects in image) \n",
    "    [2] 地标名 (Landmark Object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def va_issgz_landmark_detection(image, API_type='landmark_detection', maxResults=10):\n",
    "    \"\"\"Detects landmarks in the file.\"\"\"\n",
    "    from google.cloud import vision\n",
    "    \n",
    "##################################################################\n",
    "#     client = vision.ImageAnnotatorClient()\n",
    "# \n",
    "#     client = vision.ImageAnnotatorClient.from_service_account_json(\n",
    "#         \"/media/sf_vm_shared_folder/000-cloud-api-key/mtech-ai-7b7e049cf5f6.json\")\n",
    "##################################################################\n",
    "\n",
    "    with io.open(image, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    response = client.landmark_detection(image=image)\n",
    "    landmarks = response.landmark_annotations\n",
    "    print('Landmarks:')\n",
    "\n",
    "    image_analysis_reply = u'\\n[ ' + API_type + u' 物体识别 ]\\n'   \n",
    "    \n",
    "    \n",
    "    for landmark in landmarks:\n",
    "        print(landmark.description)\n",
    "        image_analysis_reply +=  '( ' + landmark.description + ' )\\n'\n",
    "        for location in landmark.locations:\n",
    "            lat_lng = location.lat_lng\n",
    "            print('Latitude {}'.format(lat_lng.latitude))\n",
    "            print('Longitude {}'.format(lat_lng.longitude))\n",
    "            image_analysis_reply +=  '  ' + '* Latitude  : {}'.format(lat_lng.latitude)  + '\\n'\n",
    "            image_analysis_reply +=  '  ' + '* Longitude : {}'.format(lat_lng.longitude) + '\\n'\n",
    "        \n",
    "    return image_analysis_reply    \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landmarks:\n",
      "Statue of Liberty\n",
      "Latitude 40.689261\n",
      "Longitude -74.044482\n",
      " \n",
      "=======================================================\n",
      "Formatted message is shown below for virtual assistant:\n",
      "=======================================================\n",
      "\n",
      "[ landmark_detection 物体识别 ]\n",
      "( Statue of Liberty )\n",
      "  * Latitude  : 40.689261\n",
      "  * Longitude : -74.044482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_analysis_reply = va_issgz_landmark_detection('image/new-york-statue-of-liberty.jpg')\n",
    "print(\" \")\n",
    "print(\"=======================================================\")\n",
    "print(\"Formatted message is shown below for virtual assistant:\")\n",
    "print(\"=======================================================\")\n",
    "print(image_analysis_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statue\n",
      "landmark\n",
      "monument\n",
      "sky\n",
      "organism\n",
      "artwork\n",
      "classical sculpture\n",
      "national historic landmark\n",
      "religion\n",
      " \n",
      "=======================================================\n",
      "Formatted message is shown below for virtual assistant:\n",
      "=======================================================\n",
      "\n",
      "[ label_detection 物体识别 ]\n",
      "( 0.981 : statue )\n",
      "( 0.95 : landmark )\n",
      "( 0.932 : monument )\n",
      "( 0.798 : sky )\n",
      "( 0.649 : organism )\n",
      "( 0.634 : artwork )\n",
      "( 0.603 : classical sculpture )\n",
      "( 0.601 : national historic landmark )\n",
      "( 0.515 : religion )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_analysis_reply = va_issgz_label_detection('image/new-york-statue-of-liberty.jpg')\n",
    "print(\" \")\n",
    "print(\"=======================================================\")\n",
    "print(\"Formatted message is shown below for virtual assistant:\")\n",
    "print(\"=======================================================\")\n",
    "print(image_analysis_reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### * 识别图片消息中的物体名字 (Recognize objects in image) \n",
    "    [1] 物体名 (General Object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "# 'LABEL_DETECTION'\n",
    "\n",
    "def va_issgz_label_detection(image_file, API_type='label_detection', maxResults=10):\n",
    "    \"\"\"Uses the Vision API to detect labels in the given file.\n",
    "\n",
    "    Args:\n",
    "        face_file: A file-like object containing an image with faces.\n",
    "\n",
    "    Returns:\n",
    "        An array of lABEL objects with information about the picture.\n",
    "    \"\"\"\n",
    "# \n",
    "#     client = vision.ImageAnnotatorClient.from_service_account_json(\n",
    "#         \"/media/sf_vm_shared_folder/000-cloud-api-key/mtech-ai-7b7e049cf5f6.json\")\n",
    "\n",
    "    # Loads the image into memory\n",
    "#     with open(image_file, 'rb') as image:\n",
    "    with io.open(image_file, 'rb') as image:\n",
    "        content = image.read()\n",
    "\n",
    "    image = types.Image(content=content)        \n",
    "        \n",
    "    # Performs label detection on the image file\n",
    "    response = client.label_detection(image=image)\n",
    "    labels = response.label_annotations\n",
    "\n",
    "    \n",
    "    image_analysis_reply = u'\\n[ ' + API_type + u' 物体识别 ]\\n'\n",
    "    # 'LABEL_DETECTION'\n",
    "    if labels[0].description != \"\":\n",
    "        for label in labels:\n",
    "            # Debug starts\n",
    "            print(label.description)\n",
    "            # Debug ends\n",
    "            image_analysis_reply +=  '( ' + str(round(label.score, 3)) + ' : ' + label.description + ' )\\n'\n",
    "    else:\n",
    "        image_analysis_reply += u'[ Nill 无结果 ]\\n'\n",
    "        \n",
    "    return image_analysis_reply    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n",
      "product\n",
      "presentation\n",
      "online advertising\n",
      "product\n",
      "software\n",
      "media\n",
      "font\n",
      "communication\n",
      "service\n",
      " \n",
      "========================================\n",
      "Formatted message for virtual assistant:\n",
      "========================================\n",
      "\n",
      "[ label_detection 物体识别 ]\n",
      "( 0.8938 : text )\n",
      "( 0.8076 : product )\n",
      "( 0.7253 : presentation )\n",
      "( 0.7025 : online advertising )\n",
      "( 0.6955 : product )\n",
      "( 0.6778 : software )\n",
      "( 0.6681 : media )\n",
      "( 0.6665 : font )\n",
      "( 0.6425 : communication )\n",
      "( 0.6124 : service )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_analysis_reply = va_issgz_label_detection('image/ZhanGu.png')\n",
    "print(\" \")\n",
    "print(\"=======================================================\")\n",
    "print(\"Formatted message is shown below for virtual assistant:\")\n",
    "print(\"=======================================================\")\n",
    "print(image_analysis_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入需要用到的一些功能程序库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os, subprocess, sys, time, datetime, requests, itchat\n",
    "from itchat.content import *\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Using Google Cloud Platform's Machine Learning APIs\n",
    "\n",
    "First, visit <a href=\"http://console.cloud.google.com/apis\">API console</a>, choose \"Credentials\" on the left-hand menu.  Choose \"Create Credentials\" and generate an API key for your application. You should probably restrict it by IP address to prevent abuse, but for now, just  leave that field blank and delete the API key after trying out this demo.\n",
    "\n",
    "Copy-paste your API Key here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I read in my own API_KEY from a file, which is not shared in Github repository:\n",
    "# with io.open('../../API_KEY.txt') as fp: \n",
    "#     for line in fp: APIKEY = line\n",
    "\n",
    "# You need to un-comment below line and replace 'APIKEY' variable with your own GCP API key:\n",
    "APIKEY='AIzaSyCvxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is for GCP Language Tranlation API\n",
    "service = build('translate', 'v2', developerKey=APIKEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图片二进制base64码转换 (Define image pre-processing functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the base64 encoding library.\n",
    "import base64\n",
    "# Pass the image data to an encoding function.\n",
    "def encode_image(image_file):\n",
    "    with open(image_file, \"rb\") as image_file:\n",
    "        image_content = image_file.read()\n",
    "    return base64.b64encode(image_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器智能API接口控制参数 (Define control parameters for API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# control parameter for Image API:\n",
    "parm_image_maxResults = 10 # max objects or faces to be extracted from image analysis\n",
    "\n",
    "# control parameter for Language Translation API:\n",
    "parm_translation_origin_language = '' # original language in text: to be overwriten by TEXT_DETECTION\n",
    "parm_translation_target_language = 'zh' # target language for translation: Chinese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### * 识别图片消息中的物体名字 (Recognize objects in image) \n",
    "    [1] 物体名 (General Object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "# 'LABEL_DETECTION'\n",
    "def KudosData_LABEL_DETECTION(image_base64, API_type, maxResults):\n",
    "    vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "    request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": image_base64\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': API_type,\n",
    "                    'maxResults': maxResults,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    responses = request.execute(num_retries=3)\n",
    "    image_analysis_reply = u'\\n[ ' + API_type + u' 物体识别 ]\\n'\n",
    "    # 'LABEL_DETECTION'\n",
    "    if responses['responses'][0] != {}:\n",
    "        for i in range(len(responses['responses'][0]['labelAnnotations'])):\n",
    "            image_analysis_reply += responses['responses'][0]['labelAnnotations'][i]['description'] \\\n",
    "            + '\\n( confidence ' +  str(responses['responses'][0]['labelAnnotations'][i]['score']) + ' )\\n'\n",
    "    else:\n",
    "        image_analysis_reply += u'[ Nill 无结果 ]\\n'\n",
    "        \n",
    "    return image_analysis_reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### * 识别图片消息中的物体名字 (Recognize objects in image) \n",
    "    [2] 地标名 (Landmark Object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_landmarks(path):\n",
    "    \"\"\"Detects landmarks in the file.\"\"\"\n",
    "    from google.cloud import vision\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    response = client.landmark_detection(image=image)\n",
    "    landmarks = response.landmark_annotations\n",
    "    print('Landmarks:')\n",
    "\n",
    "    for landmark in landmarks:\n",
    "        print(landmark.description)\n",
    "        for location in landmark.locations:\n",
    "            lat_lng = location.lat_lng\n",
    "            print('Latitude {}'.format(lat_lng.latitude))\n",
    "            print('Longitude {}'.format(lat_lng.longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "# 'LANDMARK_DETECTION'\n",
    "def KudosData_LANDMARK_DETECTION(image_base64, API_type, maxResults):\n",
    "    vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "    request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": image_base64\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': API_type,\n",
    "                    'maxResults': maxResults,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    responses = request.execute(num_retries=3)\n",
    "    image_analysis_reply = u'\\n[ ' + API_type + u' 地标识别 ]\\n'\n",
    "    # 'LANDMARK_DETECTION'\n",
    "    if responses['responses'][0] != {}:\n",
    "        for i in range(len(responses['responses'][0]['landmarkAnnotations'])):\n",
    "            image_analysis_reply += responses['responses'][0]['landmarkAnnotations'][i]['description'] \\\n",
    "            + '\\n( confidence ' +  str(responses['responses'][0]['landmarkAnnotations'][i]['score']) + ' )\\n'\n",
    "    else:\n",
    "        image_analysis_reply += u'[ Nill 无结果 ]\\n'\n",
    "        \n",
    "    return image_analysis_reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### * 识别图片消息中的物体名字 (Recognize objects in image) \n",
    "    [3] 商标名 (Logo Object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "# 'LOGO_DETECTION'\n",
    "def KudosData_LOGO_DETECTION(image_base64, API_type, maxResults):\n",
    "    vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "    request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": image_base64\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': API_type,\n",
    "                    'maxResults': maxResults,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    responses = request.execute(num_retries=3)\n",
    "    image_analysis_reply = u'\\n[ ' + API_type + u' 商标识别 ]\\n'\n",
    "    # 'LOGO_DETECTION'\n",
    "    if responses['responses'][0] != {}:\n",
    "        for i in range(len(responses['responses'][0]['logoAnnotations'])):\n",
    "            image_analysis_reply += responses['responses'][0]['logoAnnotations'][i]['description'] \\\n",
    "            + '\\n( confidence ' +  str(responses['responses'][0]['logoAnnotations'][i]['score']) + ' )\\n'\n",
    "    else:\n",
    "        image_analysis_reply += u'[ Nill 无结果 ]\\n'\n",
    "        \n",
    "    return image_analysis_reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### * 识别图片消息中的文字 (OCR: Extract text from image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "# 'TEXT_DETECTION'\n",
    "def KudosData_TEXT_DETECTION(image_base64, API_type, maxResults):\n",
    "    vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "    request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": image_base64\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': API_type,\n",
    "                    'maxResults': maxResults,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    responses = request.execute(num_retries=3)\n",
    "    image_analysis_reply = u'\\n[ ' + API_type + u' 文字提取 ]\\n'\n",
    "    # 'TEXT_DETECTION'\n",
    "    if responses['responses'][0] != {}:\n",
    "        image_analysis_reply += u'----- Start Original Text -----\\n'\n",
    "        image_analysis_reply += u'( Original Language 原文: ' + responses['responses'][0]['textAnnotations'][0]['locale'] \\\n",
    "        + ' )\\n'        \n",
    "        image_analysis_reply += responses['responses'][0]['textAnnotations'][0]['description'] + '----- End Original Text -----\\n'\n",
    "\n",
    "        ##############################################################################################################\n",
    "        #                                        translation of detected text                                        #\n",
    "        ##############################################################################################################\n",
    "        parm_translation_origin_language = responses['responses'][0]['textAnnotations'][0]['locale']\n",
    "        # Call translation if parm_translation_origin_language is not parm_translation_target_language\n",
    "        if parm_translation_origin_language != parm_translation_target_language:\n",
    "            inputs=[responses['responses'][0]['textAnnotations'][0]['description']] # TEXT_DETECTION OCR results only\n",
    "            outputs = service.translations().list(source=parm_translation_origin_language, \n",
    "                                                  target=parm_translation_target_language, q=inputs).execute()\n",
    "            image_analysis_reply += u'\\n----- Start Translation -----\\n'\n",
    "            image_analysis_reply += u'( Target Language 译文: ' + parm_translation_target_language + ' )\\n'\n",
    "            image_analysis_reply += outputs['translations'][0]['translatedText'] + '\\n' + '----- End Translation -----\\n'\n",
    "            print('Compeleted: Translation    API ...')\n",
    "        ##############################################################################################################\n",
    "    else:\n",
    "        image_analysis_reply += u'[ Nill 无结果 ]\\n'\n",
    "        \n",
    "    return image_analysis_reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### * 识别人脸 (Recognize human face)\n",
    "### * 基于人脸的表情来识别喜怒哀乐等情绪 (Identify sentiment and emotion from human face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "# 'FACE_DETECTION'\n",
    "def KudosData_FACE_DETECTION(image_base64, API_type, maxResults):\n",
    "    vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "    request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": image_base64\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': API_type,\n",
    "                    'maxResults': maxResults,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    responses = request.execute(num_retries=3)\n",
    "    image_analysis_reply = u'\\n[ ' + API_type + u' 面部表情 ]\\n'\n",
    "    # 'FACE_DETECTION'\n",
    "    if responses['responses'][0] != {}:\n",
    "        for i in range(len(responses['responses'][0]['faceAnnotations'])):\n",
    "            image_analysis_reply += u'----- No.' + str(i+1) + ' Face -----\\n'\n",
    "            \n",
    "            image_analysis_reply += u'>>> Joy 喜悦: \\n' \\\n",
    "            + responses['responses'][0]['faceAnnotations'][i][u'joyLikelihood'] + '\\n'\n",
    "            \n",
    "            image_analysis_reply += u'>>> Anger 愤怒: \\n' \\\n",
    "            + responses['responses'][0]['faceAnnotations'][i][u'angerLikelihood'] + '\\n'\n",
    "            \n",
    "            image_analysis_reply += u'>>> Sorrow 悲伤: \\n' \\\n",
    "            + responses['responses'][0]['faceAnnotations'][i][u'sorrowLikelihood'] + '\\n'\n",
    "            \n",
    "            image_analysis_reply += u'>>> Surprise 惊奇: \\n' \\\n",
    "            + responses['responses'][0]['faceAnnotations'][i][u'surpriseLikelihood'] + '\\n'\n",
    "            \n",
    "            image_analysis_reply += u'>>> Headwear 头饰: \\n' \\\n",
    "            + responses['responses'][0]['faceAnnotations'][i][u'headwearLikelihood'] + '\\n'\n",
    "            \n",
    "            image_analysis_reply += u'>>> Blurred 模糊: \\n' \\\n",
    "            + responses['responses'][0]['faceAnnotations'][i][u'blurredLikelihood'] + '\\n'\n",
    "            \n",
    "            image_analysis_reply += u'>>> UnderExposed 欠曝光: \\n' \\\n",
    "            + responses['responses'][0]['faceAnnotations'][i][u'underExposedLikelihood'] + '\\n'\n",
    "    else:\n",
    "        image_analysis_reply += u'[ Nill 无结果 ]\\n'\n",
    "            \n",
    "    return image_analysis_reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### * 不良内容识别 (Explicit Content Detection)\n",
    "\n",
    "Detect explicit content like adult content or violent content within an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Vision API\n",
    "# 'SAFE_SEARCH_DETECTION'\n",
    "def KudosData_SAFE_SEARCH_DETECTION(image_base64, API_type, maxResults):\n",
    "    vservice = build('vision', 'v1', developerKey=APIKEY)\n",
    "    request = vservice.images().annotate(body={\n",
    "        'requests': [{\n",
    "                'image': {\n",
    "#                     'source': {\n",
    "#                         'gcs_image_uri': IMAGE\n",
    "#                     }\n",
    "                      \"content\": image_base64\n",
    "                },\n",
    "                'features': [{\n",
    "                    'type': API_type,\n",
    "                    'maxResults': maxResults,\n",
    "                }]\n",
    "            }],\n",
    "        })\n",
    "    responses = request.execute(num_retries=3)\n",
    "    image_analysis_reply = u'\\n[ ' + API_type + u' 不良内容 ]\\n'\n",
    "    # 'SAFE_SEARCH_DETECTION'\n",
    "    if responses['responses'][0] != {}:\n",
    "        image_analysis_reply += u'>>> Adult 成人: \\n' + responses['responses'][0]['safeSearchAnnotation'][u'adult'] + '\\n'\n",
    "        image_analysis_reply += u'>>> Violence 暴力: \\n' + responses['responses'][0]['safeSearchAnnotation'][u'violence'] + '\\n'\n",
    "        image_analysis_reply += u'>>> Spoof 欺骗: \\n' + responses['responses'][0]['safeSearchAnnotation'][u'spoof'] + '\\n'\n",
    "        image_analysis_reply += u'>>> Medical 医疗: \\n' + responses['responses'][0]['safeSearchAnnotation'][u'medical'] + '\\n'\n",
    "    else:\n",
    "        image_analysis_reply += u'[ Nill 无结果 ]\\n'\n",
    "    return image_analysis_reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用微信App扫QR码图片来自动登录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itchat.auto_login(hotReload=True) # hotReload=True: 退出程序后暂存登陆状态。即使程序关闭，一定时间内重新开启也可以不用重新扫码。\n",
    "# itchat.auto_login(enableCmdQR=-2) # enableCmdQR=-2: 命令行显示QR图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @itchat.msg_register([PICTURE], isGroupChat=True)\n",
    "@itchat.msg_register([PICTURE])\n",
    "def download_files(msg):\n",
    "    parm_translation_origin_language = 'zh' # will be overwriten by TEXT_DETECTION\n",
    "    msg.download(msg.fileName)\n",
    "    print('\\nDownloaded image file name is: %s' % msg['FileName'])\n",
    "    image_base64 = encode_image(msg['FileName'])\n",
    "    \n",
    "    ##############################################################################################################\n",
    "    #                                          call image analysis APIs                                          #\n",
    "    ##############################################################################################################\n",
    "    \n",
    "    image_analysis_reply = u'[ Image Analysis 图像分析结果 ]\\n'\n",
    "\n",
    "    # 1. LABEL_DETECTION:\n",
    "    image_analysis_reply += KudosData_LABEL_DETECTION(image_base64, 'LABEL_DETECTION', parm_image_maxResults)\n",
    "    # 2. LANDMARK_DETECTION:\n",
    "    image_analysis_reply += KudosData_LANDMARK_DETECTION(image_base64, 'LANDMARK_DETECTION', parm_image_maxResults)\n",
    "    # 3. LOGO_DETECTION:\n",
    "    image_analysis_reply += KudosData_LOGO_DETECTION(image_base64, 'LOGO_DETECTION', parm_image_maxResults)\n",
    "    # 4. TEXT_DETECTION:\n",
    "    image_analysis_reply += KudosData_TEXT_DETECTION(image_base64, 'TEXT_DETECTION', parm_image_maxResults)\n",
    "    # 5. FACE_DETECTION:\n",
    "    image_analysis_reply += KudosData_FACE_DETECTION(image_base64, 'FACE_DETECTION', parm_image_maxResults)\n",
    "    # 6. SAFE_SEARCH_DETECTION:\n",
    "    image_analysis_reply += KudosData_SAFE_SEARCH_DETECTION(image_base64, 'SAFE_SEARCH_DETECTION', parm_image_maxResults)\n",
    "\n",
    "    print('Compeleted: Image Analysis API ...')\n",
    "    \n",
    "    return image_analysis_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "itchat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interupt kernel, then logout\n",
    "itchat.logout() # 安全退出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 恭喜您！已经完成了：\n",
    "### 第二课：图像识别和处理\n",
    "### Lesson 2: Image Recognition & Processing\n",
    "\n",
    "* 识别图片消息中的物体名字 (Recognize objects in image)\n",
    "        [1] 物体名 (General Object)\n",
    "        [2] 地标名 (Landmark Object)\n",
    "        [3] 商标名 (Logo Object)\n",
    "\n",
    "* 识别图片消息中的文字 (OCR: Extract text from image)\n",
    "        包含简单文本翻译 (Call text translation API)\n",
    "        \n",
    "* 识别人脸 (Recognize human face)\n",
    "        基于人脸的表情来识别喜怒哀乐等情绪 (Identify sentiment and emotion from human face)\n",
    "\n",
    "* 不良内容识别 (Explicit Content Detection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下一课是:\n",
    "### 第三课：自然语言处理：语音合成和识别\n",
    "### Lesson 3: Natural Language Processing 1\n",
    "* 消息文字转成语音 (Speech synthesis: text to voice)\n",
    "* 语音转换成消息文字 (Speech recognition: voice to text)\n",
    "* 消息文字的多语言互译 (Text based language translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='reference/WeChat_SamGu_QR.png' width=10% style=\"float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
